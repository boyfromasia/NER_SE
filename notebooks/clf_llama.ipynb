{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156b97d0-ed43-4148-8ddb-c7fe4756a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "TOKEN = \"\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f41563-3055-4a65-a343-98c221b17e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2f3f7dcfc0471d9d889c45a1160cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9263 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66fe96f064c44bcbabf9b611a29e75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2db44feb8e4922bfd6c3466dd0b005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185a4eda1dcf459b955f9e5434b21113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8023 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers.models.llama.modeling_llama import *\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "path = \"so\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train_set = load_dataset('json', data_files=os.path.join('so', 'data_train.json'))[\"train\"]\n",
    "# test_set = load_dataset('json', data_files=os.path.join('so', 'data_test.json'))[\"train\"]\n",
    "# dev_set = load_dataset('json', data_files=os.path.join('so', 'data_dev.json'))[\"train\"]\n",
    "\n",
    "dataset = load_dataset('json', data_files=os.path.join(path, 'data_train.json'), download_mode='force_redownload')\n",
    "dataset[\"test\"] = load_dataset('json', data_files=os.path.join(path, 'data_test.json'), download_mode='force_redownload')[\"train\"]\n",
    "dataset[\"validation\"] = load_dataset('json', data_files=os.path.join(path, 'data_dev.json'), download_mode='force_redownload')[\"train\"]\n",
    "dataset[\"gh\"] = load_dataset('json', data_files=os.path.join(path, 'data_gh.json'), download_mode='force_redownload')[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cfb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'O': 0, 'B-ALG': 1, 'I-ALG': 2, 'B-APP': 3, 'I-APP': 4, 'B-CB': 5, 'I-CB': 6, 'B-CLA': 7, 'I-CLA': 8, 'B-DEV': 9, 'I-DEV': 10, 'B-DS': 11, 'I-DS': 12, 'B-DT': 13, 'I-DT': 14, 'B-FN': 15, 'I-FN': 16, 'B-FT': 17, 'I-FT': 18, 'B-FUN': 19, 'I-FUN': 20, 'B-HXT': 21, 'I-HXT': 22, 'B-LAN': 23, 'I-LAN': 24, 'B-LIB': 25, 'I-LIB': 26, 'B-OS': 27, 'I-OS': 28, 'B-UIE': 29, 'I-UIE': 30, 'B-UN': 31, 'I-UN': 32, 'B-VAL': 33, 'I-VAL': 34, 'B-VAR': 35, 'I-VAR': 36, 'B-VER': 37, 'I-VER': 38, 'B-WEB': 39, 'I-WEB': 40}\n",
    "id2label = {label2id[x]: x for x in label2id}\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "max_length = 64\n",
    "lora_r = 12\n",
    "\n",
    "\n",
    "\n",
    "_CONFIG_FOR_DOC = \"LlamaConfig\"\n",
    "\n",
    "\n",
    "# Copied from transformers.models.bart.modeling_bart._make_causal_mask\n",
    "class LlamaForTokenClassification(LlamaPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = LlamaModel(config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.model.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.model.embed_tokens = value\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(LLAMA_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutputWithPast]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a06ca0-0f4f-46e9-8ccd-bdc921980aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc2f5884e6d40209dde9dc6ebc48e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForTokenClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "#base_model = \"codellama/CodeLlama-7b-hf\"\n",
    "base_model = \"meta-llama/Llama-2-7b-hf\"\n",
    "model = LlamaForTokenClassification.from_pretrained(\n",
    "    base_model, num_labels=len(label2id), id2label=id2label, label2id=label2id, token=TOKEN\n",
    ").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, token=TOKEN)\n",
    "peft_config = LoraConfig(task_type=TaskType.TOKEN_CLS, inference_mode=False, r=lora_r, lora_alpha=32, lora_dropout=0.1)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27bb5160-3363-4337-bf4c-5224e37d5e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01d8b40da8643588350c3a13dce9d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9263 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a11c1921a44a1cab8f3cce47d6a22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67889ff3fb94cf39eab96b20817b026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77928b02fec7474583f6c9448179d5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8023 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "max_length = 64\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], is_split_into_words=True, padding='longest', max_length=max_length, truncation=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4814bdc-f0e4-447d-9c70-164e21330bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "label_list = list(label2id.keys())\n",
    "\n",
    "def compute_metrics(p, full=False):\n",
    "    predictions, labels = p\n",
    "    if full is False:\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    if full:\n",
    "        return results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c32a48-d134-4445-ace3-84d1ff2d4067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11580' max='11580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11580/11580 3:17:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.235292</td>\n",
       "      <td>0.524522</td>\n",
       "      <td>0.477539</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.936399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.221530</td>\n",
       "      <td>0.575667</td>\n",
       "      <td>0.523006</td>\n",
       "      <td>0.548074</td>\n",
       "      <td>0.942548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.239381</td>\n",
       "      <td>0.563631</td>\n",
       "      <td>0.500408</td>\n",
       "      <td>0.530141</td>\n",
       "      <td>0.939833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.274167</td>\n",
       "      <td>0.527591</td>\n",
       "      <td>0.533624</td>\n",
       "      <td>0.530590</td>\n",
       "      <td>0.938488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.552686</td>\n",
       "      <td>0.512660</td>\n",
       "      <td>0.531921</td>\n",
       "      <td>0.939648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.385878</td>\n",
       "      <td>0.500756</td>\n",
       "      <td>0.541247</td>\n",
       "      <td>0.520215</td>\n",
       "      <td>0.935842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.446998</td>\n",
       "      <td>0.514393</td>\n",
       "      <td>0.520555</td>\n",
       "      <td>0.517456</td>\n",
       "      <td>0.936562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.476534</td>\n",
       "      <td>0.534552</td>\n",
       "      <td>0.509665</td>\n",
       "      <td>0.521812</td>\n",
       "      <td>0.938418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.495717</td>\n",
       "      <td>0.526448</td>\n",
       "      <td>0.512115</td>\n",
       "      <td>0.519183</td>\n",
       "      <td>0.937815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.495427</td>\n",
       "      <td>0.521018</td>\n",
       "      <td>0.512932</td>\n",
       "      <td>0.516943</td>\n",
       "      <td>0.937467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606b086-2915843148e272f131d9caf4;1c694edd-fc1a-48b0-927b-a150a5385c41)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606b526-1415593b646170cf1ea3ef79;20722006-991b-417e-b2ec-9861d3ee9eae)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606b9cc-52acceae3181df843635b846;1f965287-7d01-4feb-8a9d-bc43a79ceabc)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606be70-3b8808a03397490c2397858e;46a32cdd-e558-433e-9812-3a541ed975e2)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606c316-015861cb33692ee440a9d23a;9227bd69-a91e-40b4-906a-719082d8d419)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606c7b5-711143d30db939bb3fdad1ed;c8e61486-88ff-436e-8801-a08052b5aac2)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606cc59-7d1dbb8935179e121a38cb6e;2d62db2d-fb70-4998-859a-50642439d2b7)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606d0fc-7067b0516ccf943e708d3d21;d5762785-4263-4f2d-8b4d-fa808daa4443)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606d5a1-0a384d57715a0eb6597aecf2;83b6a37d-951c-40e9-82a2-1dababbc4ee8)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6606da42-13d078133ee710a01c023aab;d2d045bf-d103-4606-8195-aa250057e81a)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-7b-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-7b-hf.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-7b-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11580, training_loss=0.08463349342860912, metrics={'train_runtime': 11876.1604, 'train_samples_per_second': 7.8, 'train_steps_per_second': 0.975, 'total_flos': 2.3059619972289792e+17, 'train_loss': 0.08463349342860912, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"llama-with-mask\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d34533-33d8-4a6d-93d5-2a6ddcca6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"llama.txt\", \"w\") as f:\n",
    "    f.write(f\"{trainer.state.log_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de024fc-7c1f-4972-b99a-a9532c492da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "a = trainer.predict(tokenized_ds[\"validation\"])\n",
    "b = trainer.predict(tokenized_ds[\"test\"])\n",
    "c = trainer.predict(tokenized_ds[\"gh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "097f96f4-2782-42f2-bb15-5c37ef8cbb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALG': {'f1': 0.15384615384615383,\n",
      "         'number': 9,\n",
      "         'precision': 0.25,\n",
      "         'recall': 0.1111111111111111},\n",
      " 'APP': {'f1': 0.5357502517623364,\n",
      "         'number': 480,\n",
      "         'precision': 0.5185185185185185,\n",
      "         'recall': 0.5541666666666667},\n",
      " 'CB': {'f1': 0.3018867924528302,\n",
      "        'number': 244,\n",
      "        'precision': 0.27972027972027974,\n",
      "        'recall': 0.32786885245901637},\n",
      " 'CLA': {'f1': 0.4833538840937115,\n",
      "         'number': 406,\n",
      "         'precision': 0.4839506172839506,\n",
      "         'recall': 0.4827586206896552},\n",
      " 'DEV': {'f1': 0.5267489711934157,\n",
      "         'number': 149,\n",
      "         'precision': 0.6808510638297872,\n",
      "         'recall': 0.42953020134228187},\n",
      " 'DS': {'f1': 0.6956521739130435,\n",
      "        'number': 177,\n",
      "        'precision': 0.7142857142857143,\n",
      "        'recall': 0.6779661016949152},\n",
      " 'DT': {'f1': 0.7490039840637451,\n",
      "        'number': 134,\n",
      "        'precision': 0.8034188034188035,\n",
      "        'recall': 0.7014925373134329},\n",
      " 'FN': {'f1': 0.3004291845493562,\n",
      "        'number': 134,\n",
      "        'precision': 0.35353535353535354,\n",
      "        'recall': 0.26119402985074625},\n",
      " 'FT': {'f1': 0.5641025641025642,\n",
      "        'number': 90,\n",
      "        'precision': 0.5238095238095238,\n",
      "        'recall': 0.6111111111111112},\n",
      " 'FUN': {'f1': 0.42462845010615713,\n",
      "         'number': 261,\n",
      "         'precision': 0.47619047619047616,\n",
      "         'recall': 0.3831417624521073},\n",
      " 'HXT': {'f1': 0.6588235294117647,\n",
      "         'number': 38,\n",
      "         'precision': 0.5957446808510638,\n",
      "         'recall': 0.7368421052631579},\n",
      " 'LAN': {'f1': 0.7554179566563467,\n",
      "         'number': 154,\n",
      "         'precision': 0.7218934911242604,\n",
      "         'recall': 0.7922077922077922},\n",
      " 'LIB': {'f1': 0.48085106382978726,\n",
      "         'number': 226,\n",
      "         'precision': 0.46311475409836067,\n",
      "         'recall': 0.5},\n",
      " 'OS': {'f1': 0.7801418439716311,\n",
      "        'number': 73,\n",
      "        'precision': 0.8088235294117647,\n",
      "        'recall': 0.7534246575342466},\n",
      " 'UIE': {'f1': 0.5569230769230769,\n",
      "         'number': 330,\n",
      "         'precision': 0.565625,\n",
      "         'recall': 0.5484848484848485},\n",
      " 'UN': {'f1': 0.47058823529411764,\n",
      "        'number': 30,\n",
      "        'precision': 0.5714285714285714,\n",
      "        'recall': 0.4},\n",
      " 'VAL': {'f1': 0.44556113902847577,\n",
      "         'number': 269,\n",
      "         'precision': 0.4054878048780488,\n",
      "         'recall': 0.4944237918215613},\n",
      " 'VAR': {'f1': 0.3568773234200743,\n",
      "         'number': 293,\n",
      "         'precision': 0.39183673469387753,\n",
      "         'recall': 0.32764505119453924},\n",
      " 'VER': {'f1': 0.838235294117647,\n",
      "         'number': 137,\n",
      "         'precision': 0.8444444444444444,\n",
      "         'recall': 0.8321167883211679},\n",
      " 'WEB': {'f1': 0.49350649350649345,\n",
      "         'number': 39,\n",
      "         'precision': 0.5,\n",
      "         'recall': 0.48717948717948717},\n",
      " 'overall_accuracy': 0.9374666450100935,\n",
      " 'overall_f1': 0.5169433392783647,\n",
      " 'overall_precision': 0.5210176991150443,\n",
      " 'overall_recall': 0.5129322080043561}\n",
      "{'ALG': {'f1': 0.25, 'number': 16, 'precision': 0.375, 'recall': 0.1875},\n",
      " 'APP': {'f1': 0.5366430260047281,\n",
      "         'number': 407,\n",
      "         'precision': 0.5170842824601367,\n",
      "         'recall': 0.5577395577395577},\n",
      " 'CB': {'f1': 0.29605263157894735,\n",
      "        'number': 294,\n",
      "        'precision': 0.28662420382165604,\n",
      "        'recall': 0.30612244897959184},\n",
      " 'CLA': {'f1': 0.4793388429752066,\n",
      "         'number': 509,\n",
      "         'precision': 0.5054466230936819,\n",
      "         'recall': 0.45579567779960706},\n",
      " 'DEV': {'f1': 0.47058823529411764,\n",
      "         'number': 53,\n",
      "         'precision': 0.42424242424242425,\n",
      "         'recall': 0.5283018867924528},\n",
      " 'DS': {'f1': 0.7599999999999999,\n",
      "        'number': 244,\n",
      "        'precision': 0.8300970873786407,\n",
      "        'recall': 0.7008196721311475},\n",
      " 'DT': {'f1': 0.7623318385650223,\n",
      "        'number': 111,\n",
      "        'precision': 0.7589285714285714,\n",
      "        'recall': 0.7657657657657657},\n",
      " 'FN': {'f1': 0.36296296296296293,\n",
      "        'number': 163,\n",
      "        'precision': 0.45794392523364486,\n",
      "        'recall': 0.3006134969325153},\n",
      " 'FT': {'f1': 0.581497797356828,\n",
      "        'number': 127,\n",
      "        'precision': 0.66,\n",
      "        'recall': 0.5196850393700787},\n",
      " 'FUN': {'f1': 0.44223107569721115,\n",
      "         'number': 266,\n",
      "         'precision': 0.4703389830508475,\n",
      "         'recall': 0.41729323308270677},\n",
      " 'HXT': {'f1': 0.4999999999999999,\n",
      "         'number': 52,\n",
      "         'precision': 0.5454545454545454,\n",
      "         'recall': 0.46153846153846156},\n",
      " 'LAN': {'f1': 0.7288135593220338,\n",
      "         'number': 178,\n",
      "         'precision': 0.7329545454545454,\n",
      "         'recall': 0.7247191011235955},\n",
      " 'LIB': {'f1': 0.4418604651162791,\n",
      "         'number': 257,\n",
      "         'precision': 0.44015444015444016,\n",
      "         'recall': 0.44357976653696496},\n",
      " 'OS': {'f1': 0.7692307692307692,\n",
      "        'number': 66,\n",
      "        'precision': 0.78125,\n",
      "        'recall': 0.7575757575757576},\n",
      " 'UIE': {'f1': 0.5236842105263159,\n",
      "         'number': 355,\n",
      "         'precision': 0.49135802469135803,\n",
      "         'recall': 0.5605633802816902},\n",
      " 'UN': {'f1': 0.4090909090909091,\n",
      "        'number': 24,\n",
      "        'precision': 0.45,\n",
      "        'recall': 0.375},\n",
      " 'VAL': {'f1': 0.4568764568764569,\n",
      "         'number': 213,\n",
      "         'precision': 0.4537037037037037,\n",
      "         'recall': 0.460093896713615},\n",
      " 'VAR': {'f1': 0.3977110157367668,\n",
      "         'number': 375,\n",
      "         'precision': 0.42901234567901236,\n",
      "         'recall': 0.37066666666666664},\n",
      " 'VER': {'f1': 0.8272727272727273,\n",
      "         'number': 111,\n",
      "         'precision': 0.8348623853211009,\n",
      "         'recall': 0.8198198198198198},\n",
      " 'WEB': {'f1': 0.5671641791044776,\n",
      "         'number': 39,\n",
      "         'precision': 0.6785714285714286,\n",
      "         'recall': 0.48717948717948717},\n",
      " 'overall_accuracy': 0.9380692971041662,\n",
      " 'overall_f1': 0.5121822033898306,\n",
      " 'overall_precision': 0.5238353196099675,\n",
      " 'overall_recall': 0.5010362694300519}\n",
      "{'ALG': {'f1': 0.028571428571428574,\n",
      "         'number': 53,\n",
      "         'precision': 0.058823529411764705,\n",
      "         'recall': 0.018867924528301886},\n",
      " 'APP': {'f1': 0.44415243101182655,\n",
      "         'number': 1224,\n",
      "         'precision': 0.47875354107648727,\n",
      "         'recall': 0.41421568627450983},\n",
      " 'CB': {'f1': 0.23292595255212079,\n",
      "        'number': 555,\n",
      "        'precision': 0.1937799043062201,\n",
      "        'recall': 0.2918918918918919},\n",
      " 'CLA': {'f1': 0.21153846153846154,\n",
      "         'number': 274,\n",
      "         'precision': 0.1696035242290749,\n",
      "         'recall': 0.28102189781021897},\n",
      " 'DEV': {'f1': 0.4088050314465409,\n",
      "         'number': 153,\n",
      "         'precision': 0.3939393939393939,\n",
      "         'recall': 0.42483660130718953},\n",
      " 'DS': {'f1': 0.6169491525423729,\n",
      "        'number': 156,\n",
      "        'precision': 0.6546762589928058,\n",
      "        'recall': 0.5833333333333334},\n",
      " 'DT': {'f1': 0.36619718309859156,\n",
      "        'number': 85,\n",
      "        'precision': 0.45614035087719296,\n",
      "        'recall': 0.3058823529411765},\n",
      " 'FN': {'f1': 0.25999999999999995,\n",
      "        'number': 227,\n",
      "        'precision': 0.23809523809523808,\n",
      "        'recall': 0.28634361233480177},\n",
      " 'FT': {'f1': 0.43708609271523186,\n",
      "        'number': 138,\n",
      "        'precision': 0.4024390243902439,\n",
      "        'recall': 0.4782608695652174},\n",
      " 'FUN': {'f1': 0.23255813953488372,\n",
      "         'number': 143,\n",
      "         'precision': 0.18442622950819673,\n",
      "         'recall': 0.3146853146853147},\n",
      " 'HXT': {'f1': 0.23529411764705882,\n",
      "         'number': 13,\n",
      "         'precision': 0.19047619047619047,\n",
      "         'recall': 0.3076923076923077},\n",
      " 'LAN': {'f1': 0.6968325791855203,\n",
      "         'number': 209,\n",
      "         'precision': 0.6609442060085837,\n",
      "         'recall': 0.7368421052631579},\n",
      " 'LIB': {'f1': 0.3141025641025641,\n",
      "         'number': 579,\n",
      "         'precision': 0.2929745889387145,\n",
      "         'recall': 0.3385146804835924},\n",
      " 'OS': {'f1': 0.8165680473372781,\n",
      "        'number': 175,\n",
      "        'precision': 0.8466257668711656,\n",
      "        'recall': 0.7885714285714286},\n",
      " 'UIE': {'f1': 0.5238879736408566,\n",
      "         'number': 282,\n",
      "         'precision': 0.48923076923076925,\n",
      "         'recall': 0.5638297872340425},\n",
      " 'UN': {'f1': 0.4244186046511628,\n",
      "        'number': 182,\n",
      "        'precision': 0.4506172839506173,\n",
      "        'recall': 0.4010989010989011},\n",
      " 'VAL': {'f1': 0.0, 'number': 0, 'precision': 0.0, 'recall': 0.0},\n",
      " 'VAR': {'f1': 0.12711864406779663,\n",
      "         'number': 348,\n",
      "         'precision': 0.10067114093959731,\n",
      "         'recall': 0.1724137931034483},\n",
      " 'VER': {'f1': 0.6733001658374793,\n",
      "         'number': 333,\n",
      "         'precision': 0.7518518518518519,\n",
      "         'recall': 0.6096096096096096},\n",
      " 'WEB': {'f1': 0.45267489711934156,\n",
      "         'number': 145,\n",
      "         'precision': 0.5612244897959183,\n",
      "         'recall': 0.3793103448275862},\n",
      " 'overall_accuracy': 0.9089015641378184,\n",
      " 'overall_f1': 0.36713406292749656,\n",
      " 'overall_precision': 0.3343195266272189,\n",
      " 'overall_recall': 0.40709139173302994}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "def get_dct(x, text):\n",
    "    pred = np.argmax(x.predictions, axis=2)\n",
    "    dct = compute_metrics((pred, tokenized_ds[text][\"labels\"]), True)\n",
    "    with open(f'llama_{text}.pickle', 'wb') as f:\n",
    "        pickle.dump(dct, f)\n",
    "\n",
    "    return dct\n",
    "\n",
    "pprint(get_dct(a, \"validation\"))\n",
    "pprint(get_dct(b, \"test\"))\n",
    "pprint(get_dct(c, \"gh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9319b33-70f9-4276-86d6-d183521fd0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeGen",
   "language": "python",
   "name": "codegen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
