{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeMEteliuHRF",
    "is_executing": true,
    "outputId": "429cdcc0-99a4-4b76-c994-e004e25850c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abuboba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    MT5ForConditionalGeneration,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5TokenizerFast,\n",
    "    AutoTokenizer,\n",
    "    T5ForTokenClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "label2id = {'O': 0, 'B-ALG': 1, 'I-ALG': 2, 'B-APP': 3, 'I-APP': 4, 'B-CB': 5, 'I-CB': 6, 'B-CLA': 7, 'I-CLA': 8, 'B-DEV': 9, 'I-DEV': 10, 'B-DS': 11, 'I-DS': 12, 'B-DT': 13, 'I-DT': 14, 'B-FN': 15, 'I-FN': 16, 'B-FT': 17, 'I-FT': 18, 'B-FUN': 19, 'I-FUN': 20, 'B-HXT': 21, 'I-HXT': 22, 'B-LAN': 23, 'I-LAN': 24, 'B-LIB': 25, 'I-LIB': 26, 'B-OS': 27, 'I-OS': 28, 'B-UIE': 29, 'I-UIE': 30, 'B-UN': 31, 'I-UN': 32, 'B-VAL': 33, 'I-VAL': 34, 'B-VAR': 35, 'I-VAR': 36, 'B-VER': 37, 'I-VER': 38, 'B-WEB': 39, 'I-WEB': 40}\n",
    "id2label = {label2id[x]: x for x in label2id}\n",
    "labels = ['Algorithm', 'Application', 'Class', 'Code_Block', 'Data_Structure', 'Data_Type', 'Device', 'File_Name', 'File_Type', 'Function', 'HTML_XML_Tag', 'Language', 'Library', 'Operating_System', 'User_Interface_Element', 'User_Name', 'Value', 'Variable', 'Version', 'Website']\n",
    "labels_short = ['ALG', 'APP', 'CB', 'CLA', 'DEV', 'DS', 'DT', 'FN', 'FT', 'FUN', 'HXT', 'LAN', 'LIB', 'OS', 'UIE', 'UN', 'VAL', 'VAR', 'VER', 'WEB']\n",
    "short2long = {'ALG': 'Algorithm', 'APP': 'Application', 'CB': 'Class', 'CLA': 'Code_Block', 'DEV': 'Data_Structure', 'DS': 'Data_Type', 'DT': 'Device', 'FN': 'File_Name', 'FT': 'File_Type', 'FUN': 'Function', 'HXT': 'HTML_XML_Tag', 'LAN': 'Language', 'LIB': 'Library', 'OS': 'Operating_System', 'UIE': 'User_Interface_Element', 'UN': 'User_Name', 'VAL': 'Value', 'VAR': 'Variable', 'VER': 'Version', 'WEB': 'Website'}\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "model_checkpoint_path = f\"checkpoints/{model_name}-token-clf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:31:13.249774400Z",
     "start_time": "2024-02-27T07:31:10.496275200Z"
    },
    "id": "cduCgNT3uREP"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('json', data_files=os.path.join('data\\StackOverflow\\json', 'data_train.json'))\n",
    "dataset[\"test\"] = load_dataset('json', data_files=os.path.join('data\\StackOverflow\\json', 'data_test.json'))[\"train\"]\n",
    "dataset[\"validation\"] = load_dataset('json', data_files=os.path.join('data\\StackOverflow\\json', 'data_dev.json'))[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:31:17.029396Z",
     "start_time": "2024-02-27T07:31:13.252778600Z"
    },
    "id": "V33SesdCuURn"
   },
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:31:17.038352600Z",
     "start_time": "2024-02-27T07:31:17.031396Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRqpLfxaxKM_",
    "outputId": "56e6a116-0225-4cbf-9f85-56f70514364f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁If', '▁I', '▁would', '▁have', '▁2', '▁tables', '</s>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:31:17.045990200Z",
     "start_time": "2024-02-27T07:31:17.038352600Z"
    },
    "id": "0ECkNyjLxQwK"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:31:17.928320300Z",
     "start_time": "2024-02-27T07:31:17.044990300Z"
    },
    "id": "XEJCv5UnxjsA"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:31:17.940053300Z",
     "start_time": "2024-02-27T07:31:17.929318900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pP5msi4VyB1f",
    "outputId": "0fe1c82e-26e4-453e-e62e-a01e42ed253a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'spans', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9263\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'spans', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3108\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'spans', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2936\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:31:17.947565100Z",
     "start_time": "2024-02-27T07:31:17.934055700Z"
    },
    "id": "JswfV0oNyKSx"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:31:19.947481700Z",
     "start_time": "2024-02-27T07:31:18.313882500Z"
    },
    "id": "DTO5IsERyaEZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "label_list = list(label2id.keys())\n",
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "\n",
    "\n",
    "def compute_metrics(p, full=False):\n",
    "    predictions, labels = p\n",
    "\n",
    "    if full is False:\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    if full:\n",
    "        return results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afL0NRbszVwo",
    "outputId": "bce3849b-b2a5-4fd7-b680-45e984019f26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForTokenClassification were not initialized from the model checkpoint at t5-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model = T5ForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id, device_map='cuda'\n",
    ")\n",
    "model.model_parallel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kvFCjbQmzp_I",
    "outputId": "a51f2f76-8211-4ec8-a25f-8ae6f4dc6355"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11580' max='11580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11580/11580 10:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.641300</td>\n",
       "      <td>0.468289</td>\n",
       "      <td>0.179510</td>\n",
       "      <td>0.109333</td>\n",
       "      <td>0.135896</td>\n",
       "      <td>0.899968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.485200</td>\n",
       "      <td>0.389043</td>\n",
       "      <td>0.265260</td>\n",
       "      <td>0.225176</td>\n",
       "      <td>0.243580</td>\n",
       "      <td>0.909345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.353080</td>\n",
       "      <td>0.326195</td>\n",
       "      <td>0.285133</td>\n",
       "      <td>0.304285</td>\n",
       "      <td>0.916205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.330442</td>\n",
       "      <td>0.370189</td>\n",
       "      <td>0.328812</td>\n",
       "      <td>0.348276</td>\n",
       "      <td>0.920893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.314810</td>\n",
       "      <td>0.391459</td>\n",
       "      <td>0.358112</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>0.923896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.304625</td>\n",
       "      <td>0.404964</td>\n",
       "      <td>0.376289</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.925928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.296683</td>\n",
       "      <td>0.414571</td>\n",
       "      <td>0.393652</td>\n",
       "      <td>0.403841</td>\n",
       "      <td>0.927130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.293422</td>\n",
       "      <td>0.427737</td>\n",
       "      <td>0.397450</td>\n",
       "      <td>0.412038</td>\n",
       "      <td>0.928446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.290288</td>\n",
       "      <td>0.421646</td>\n",
       "      <td>0.405860</td>\n",
       "      <td>0.413602</td>\n",
       "      <td>0.928423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.289394</td>\n",
       "      <td>0.428246</td>\n",
       "      <td>0.408030</td>\n",
       "      <td>0.417894</td>\n",
       "      <td>0.928862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abuboba\\.conda\\envs\\Assignment1_PMLDL\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11580, training_loss=0.41138603345511904, metrics={'train_runtime': 613.0499, 'train_samples_per_second': 151.097, 'train_steps_per_second': 18.889, 'total_flos': 492913061037426.0, 'train_loss': 0.41138603345511904, 'epoch': 10.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_checkpoint_path,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:32:03.940324600Z",
     "start_time": "2024-02-27T07:31:34.740853Z"
    },
    "id": "3RtsS24eH8G5"
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "# model = T5ForTokenClassification.from_pretrained(\n",
    "#     \"t5-token-clf-low\", num_labels=len(label2id), id2label=id2label, label2id=label2id, device_map='balanced'\n",
    "# ).to(\"cuda\")\n",
    "\n",
    "for item in tokenized_dataset[\"test\"]:\n",
    "    a = tokenizer(item[\"tokens\"],truncation=True, padding=True,is_split_into_words=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    predictions = np.argmax(model(**a).logits.cpu().detach(), axis=2)\n",
    "    pred.extend(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:32:04.688093700Z",
     "start_time": "2024-02-27T07:32:03.942324300Z"
    },
    "id": "F0BLdeRqEjsK"
   },
   "outputs": [],
   "source": [
    "dct = compute_metrics((pred, tokenized_dataset[\"test\"][\"labels\"]), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T07:32:04.696090Z",
     "start_time": "2024-02-27T07:32:04.690090900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Of0bu3RUP1zA",
    "outputId": "b551b64e-4271-41d7-90b7-7e8e4f12519e"
   },
   "outputs": [],
   "source": [
    "for x in dct:\n",
    "    print(x, \"---\", dct[x], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"t5-small.txt\", \"w\") as f:\n",
    "    f.write(f\"{trainer.state.log_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
