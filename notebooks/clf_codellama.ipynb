{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156b97d0-ed43-4148-8ddb-c7fe4756a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "TOKEN = \"\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f41563-3055-4a65-a343-98c221b17e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50914d4ec59d47d8b0fd9021344261fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9263 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1f446399884c989b43b2b2316649f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09faeb24719f4a2986bc953b9aecb74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b364488de34c82b350528598aecdb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8023 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers.models.llama.modeling_llama import *\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "path = \"so\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train_set = load_dataset('json', data_files=os.path.join('so', 'data_train.json'))[\"train\"]\n",
    "# test_set = load_dataset('json', data_files=os.path.join('so', 'data_test.json'))[\"train\"]\n",
    "# dev_set = load_dataset('json', data_files=os.path.join('so', 'data_dev.json'))[\"train\"]\n",
    "\n",
    "dataset = load_dataset('json', data_files=os.path.join(path, 'data_train.json'), download_mode='force_redownload')\n",
    "dataset[\"test\"] = load_dataset('json', data_files=os.path.join(path, 'data_test.json'), download_mode='force_redownload')[\"train\"]\n",
    "dataset[\"validation\"] = load_dataset('json', data_files=os.path.join(path, 'data_dev.json'), download_mode='force_redownload')[\"train\"]\n",
    "dataset[\"gh\"] = load_dataset('json', data_files=os.path.join(path, 'data_gh.json'), download_mode='force_redownload')[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cfb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'O': 0, 'B-ALG': 1, 'I-ALG': 2, 'B-APP': 3, 'I-APP': 4, 'B-CB': 5, 'I-CB': 6, 'B-CLA': 7, 'I-CLA': 8, 'B-DEV': 9, 'I-DEV': 10, 'B-DS': 11, 'I-DS': 12, 'B-DT': 13, 'I-DT': 14, 'B-FN': 15, 'I-FN': 16, 'B-FT': 17, 'I-FT': 18, 'B-FUN': 19, 'I-FUN': 20, 'B-HXT': 21, 'I-HXT': 22, 'B-LAN': 23, 'I-LAN': 24, 'B-LIB': 25, 'I-LIB': 26, 'B-OS': 27, 'I-OS': 28, 'B-UIE': 29, 'I-UIE': 30, 'B-UN': 31, 'I-UN': 32, 'B-VAL': 33, 'I-VAL': 34, 'B-VAR': 35, 'I-VAR': 36, 'B-VER': 37, 'I-VER': 38, 'B-WEB': 39, 'I-WEB': 40}\n",
    "id2label = {label2id[x]: x for x in label2id}\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "max_length = 64\n",
    "lora_r = 12\n",
    "\n",
    "\n",
    "\n",
    "_CONFIG_FOR_DOC = \"LlamaConfig\"\n",
    "\n",
    "\n",
    "# Copied from transformers.models.bart.modeling_bart._make_causal_mask\n",
    "class LlamaForTokenClassification(LlamaPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = LlamaModel(config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.model.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.model.embed_tokens = value\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(LLAMA_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutputWithPast]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a06ca0-0f4f-46e9-8ccd-bdc921980aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa456bb2a2f4951b4a0e2080d6e21f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForTokenClassification were not initialized from the model checkpoint at codellama/CodeLlama-7b-hf and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "base_model = \"codellama/CodeLlama-7b-hf\"\n",
    "# base_model = \"meta-llama/Llama-2-7b-hf\"\n",
    "model = LlamaForTokenClassification.from_pretrained(\n",
    "    base_model, num_labels=len(label2id), id2label=id2label, label2id=label2id, token=TOKEN\n",
    ").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, token=TOKEN)\n",
    "peft_config = LoraConfig(task_type=TaskType.TOKEN_CLS, inference_mode=False, r=lora_r, lora_alpha=32, lora_dropout=0.1)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27bb5160-3363-4337-bf4c-5224e37d5e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac9b0af41844b798bba88ec8b1b670a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9263 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7addf39e074f2f9258d77c959cbe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c4d41fa9714e0da6ddad201a9d7280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9846d5cdf14b5da0c2de177d48da36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8023 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "max_length = 64\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], is_split_into_words=True, padding='longest', max_length=max_length, truncation=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4814bdc-f0e4-447d-9c70-164e21330bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "label_list = list(label2id.keys())\n",
    "\n",
    "def compute_metrics(p, full=False):\n",
    "    predictions, labels = p\n",
    "    if full is False:\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    if full:\n",
    "        return results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c32a48-d134-4445-ace3-84d1ff2d4067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11580' max='11580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11580/11580 3:18:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>0.232199</td>\n",
       "      <td>0.545981</td>\n",
       "      <td>0.488157</td>\n",
       "      <td>0.515452</td>\n",
       "      <td>0.937443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.217917</td>\n",
       "      <td>0.583920</td>\n",
       "      <td>0.541791</td>\n",
       "      <td>0.562068</td>\n",
       "      <td>0.943755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.242778</td>\n",
       "      <td>0.588108</td>\n",
       "      <td>0.519739</td>\n",
       "      <td>0.551814</td>\n",
       "      <td>0.940785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.259627</td>\n",
       "      <td>0.559051</td>\n",
       "      <td>0.532262</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>0.940321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>0.563873</td>\n",
       "      <td>0.531173</td>\n",
       "      <td>0.547035</td>\n",
       "      <td>0.940344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.312592</td>\n",
       "      <td>0.523301</td>\n",
       "      <td>0.547237</td>\n",
       "      <td>0.535001</td>\n",
       "      <td>0.937095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.352507</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.531446</td>\n",
       "      <td>0.536854</td>\n",
       "      <td>0.938534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.377543</td>\n",
       "      <td>0.548146</td>\n",
       "      <td>0.519194</td>\n",
       "      <td>0.533277</td>\n",
       "      <td>0.938464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.389155</td>\n",
       "      <td>0.544782</td>\n",
       "      <td>0.521644</td>\n",
       "      <td>0.532962</td>\n",
       "      <td>0.938441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.399247</td>\n",
       "      <td>0.539540</td>\n",
       "      <td>0.523822</td>\n",
       "      <td>0.531565</td>\n",
       "      <td>0.938372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11580, training_loss=0.0833618023646722, metrics={'train_runtime': 11933.8665, 'train_samples_per_second': 7.762, 'train_steps_per_second': 0.97, 'total_flos': 2.3059619972289792e+17, 'train_loss': 0.0833618023646722, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"codellama-with-mask\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d34533-33d8-4a6d-93d5-2a6ddcca6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"codellama.txt\", \"w\") as f:\n",
    "    f.write(f\"{trainer.state.log_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d2dfbe-b383-4b7b-b2fd-69810577a049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/codeGen/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "a = trainer.predict(tokenized_ds[\"validation\"])\n",
    "b = trainer.predict(tokenized_ds[\"test\"])\n",
    "c = trainer.predict(tokenized_ds[\"gh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f069b2ac-893b-44a6-8ed4-2b1bfddfa806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ALG': {'f1': 0.0, 'number': 9, 'precision': 0.0, 'recall': 0.0},\n",
      " 'APP': {'f1': 0.5393939393939394,\n",
      "         'number': 480,\n",
      "         'precision': 0.5235294117647059,\n",
      "         'recall': 0.55625},\n",
      " 'CB': {'f1': 0.3436293436293436,\n",
      "        'number': 244,\n",
      "        'precision': 0.3248175182481752,\n",
      "        'recall': 0.36475409836065575},\n",
      " 'CLA': {'f1': 0.4993662864385298,\n",
      "         'number': 406,\n",
      "         'precision': 0.5143603133159269,\n",
      "         'recall': 0.4852216748768473},\n",
      " 'DEV': {'f1': 0.5461254612546126,\n",
      "         'number': 149,\n",
      "         'precision': 0.6065573770491803,\n",
      "         'recall': 0.4966442953020134},\n",
      " 'DS': {'f1': 0.7048710601719198,\n",
      "        'number': 177,\n",
      "        'precision': 0.7151162790697675,\n",
      "        'recall': 0.6949152542372882},\n",
      " 'DT': {'f1': 0.7389558232931727,\n",
      "        'number': 134,\n",
      "        'precision': 0.8,\n",
      "        'recall': 0.6865671641791045},\n",
      " 'FN': {'f1': 0.3619047619047619,\n",
      "        'number': 134,\n",
      "        'precision': 0.5,\n",
      "        'recall': 0.2835820895522388},\n",
      " 'FT': {'f1': 0.5876288659793815,\n",
      "        'number': 90,\n",
      "        'precision': 0.5480769230769231,\n",
      "        'recall': 0.6333333333333333},\n",
      " 'FUN': {'f1': 0.4728033472803347,\n",
      "         'number': 261,\n",
      "         'precision': 0.5207373271889401,\n",
      "         'recall': 0.4329501915708812},\n",
      " 'HXT': {'f1': 0.5925925925925927,\n",
      "         'number': 38,\n",
      "         'precision': 0.5581395348837209,\n",
      "         'recall': 0.631578947368421},\n",
      " 'LAN': {'f1': 0.7801857585139319,\n",
      "         'number': 154,\n",
      "         'precision': 0.7455621301775148,\n",
      "         'recall': 0.8181818181818182},\n",
      " 'LIB': {'f1': 0.43644067796610175,\n",
      "         'number': 226,\n",
      "         'precision': 0.4186991869918699,\n",
      "         'recall': 0.4557522123893805},\n",
      " 'OS': {'f1': 0.7837837837837838,\n",
      "        'number': 73,\n",
      "        'precision': 0.7733333333333333,\n",
      "        'recall': 0.7945205479452054},\n",
      " 'UIE': {'f1': 0.5768621236133122,\n",
      "         'number': 330,\n",
      "         'precision': 0.6046511627906976,\n",
      "         'recall': 0.5515151515151515},\n",
      " 'UN': {'f1': 0.56,\n",
      "        'number': 30,\n",
      "        'precision': 0.7,\n",
      "        'recall': 0.4666666666666667},\n",
      " 'VAL': {'f1': 0.4612736660929432,\n",
      "         'number': 269,\n",
      "         'precision': 0.42948717948717946,\n",
      "         'recall': 0.49814126394052044},\n",
      " 'VAR': {'f1': 0.358695652173913,\n",
      "         'number': 293,\n",
      "         'precision': 0.38223938223938225,\n",
      "         'recall': 0.3378839590443686},\n",
      " 'VER': {'f1': 0.8549618320610687,\n",
      "         'number': 137,\n",
      "         'precision': 0.896,\n",
      "         'recall': 0.8175182481751825},\n",
      " 'WEB': {'f1': 0.55,\n",
      "         'number': 39,\n",
      "         'precision': 0.5365853658536586,\n",
      "         'recall': 0.5641025641025641},\n",
      " 'overall_accuracy': 0.9383715803884262,\n",
      " 'overall_f1': 0.5315651333057052,\n",
      " 'overall_precision': 0.5395401009534493,\n",
      " 'overall_recall': 0.5238224884290771}\n",
      "{'ALG': {'f1': 0.43478260869565216,\n",
      "         'number': 16,\n",
      "         'precision': 0.7142857142857143,\n",
      "         'recall': 0.3125},\n",
      " 'APP': {'f1': 0.5322391559202814,\n",
      "         'number': 407,\n",
      "         'precision': 0.5089686098654709,\n",
      "         'recall': 0.5577395577395577},\n",
      " 'CB': {'f1': 0.3010033444816053,\n",
      "        'number': 294,\n",
      "        'precision': 0.29605263157894735,\n",
      "        'recall': 0.30612244897959184},\n",
      " 'CLA': {'f1': 0.5539070227497528,\n",
      "         'number': 509,\n",
      "         'precision': 0.5577689243027888,\n",
      "         'recall': 0.550098231827112},\n",
      " 'DEV': {'f1': 0.5405405405405406,\n",
      "         'number': 53,\n",
      "         'precision': 0.5172413793103449,\n",
      "         'recall': 0.5660377358490566},\n",
      " 'DS': {'f1': 0.7866666666666666,\n",
      "        'number': 244,\n",
      "        'precision': 0.8592233009708737,\n",
      "        'recall': 0.7254098360655737},\n",
      " 'DT': {'f1': 0.7339449541284405,\n",
      "        'number': 111,\n",
      "        'precision': 0.7476635514018691,\n",
      "        'recall': 0.7207207207207207},\n",
      " 'FN': {'f1': 0.458498023715415,\n",
      "        'number': 163,\n",
      "        'precision': 0.6444444444444445,\n",
      "        'recall': 0.3558282208588957},\n",
      " 'FT': {'f1': 0.5974025974025974,\n",
      "        'number': 127,\n",
      "        'precision': 0.6634615384615384,\n",
      "        'recall': 0.5433070866141733},\n",
      " 'FUN': {'f1': 0.4316831683168317,\n",
      "         'number': 266,\n",
      "         'precision': 0.4560669456066946,\n",
      "         'recall': 0.40977443609022557},\n",
      " 'HXT': {'f1': 0.42696629213483145,\n",
      "         'number': 52,\n",
      "         'precision': 0.5135135135135135,\n",
      "         'recall': 0.36538461538461536},\n",
      " 'LAN': {'f1': 0.7119565217391305,\n",
      "         'number': 178,\n",
      "         'precision': 0.6894736842105263,\n",
      "         'recall': 0.7359550561797753},\n",
      " 'LIB': {'f1': 0.45849802371541504,\n",
      "         'number': 257,\n",
      "         'precision': 0.46586345381526106,\n",
      "         'recall': 0.45136186770428016},\n",
      " 'OS': {'f1': 0.8031496062992125,\n",
      "        'number': 66,\n",
      "        'precision': 0.8360655737704918,\n",
      "        'recall': 0.7727272727272727},\n",
      " 'UIE': {'f1': 0.577023498694517,\n",
      "         'number': 355,\n",
      "         'precision': 0.537712895377129,\n",
      "         'recall': 0.6225352112676056},\n",
      " 'UN': {'f1': 0.39285714285714285,\n",
      "        'number': 24,\n",
      "        'precision': 0.34375,\n",
      "        'recall': 0.4583333333333333},\n",
      " 'VAL': {'f1': 0.4587155963302752,\n",
      "         'number': 213,\n",
      "         'precision': 0.4484304932735426,\n",
      "         'recall': 0.4694835680751174},\n",
      " 'VAR': {'f1': 0.4102564102564103,\n",
      "         'number': 375,\n",
      "         'precision': 0.44036697247706424,\n",
      "         'recall': 0.384},\n",
      " 'VER': {'f1': 0.8493150684931507,\n",
      "         'number': 111,\n",
      "         'precision': 0.8611111111111112,\n",
      "         'recall': 0.8378378378378378},\n",
      " 'WEB': {'f1': 0.4571428571428572,\n",
      "         'number': 39,\n",
      "         'precision': 0.5161290322580645,\n",
      "         'recall': 0.41025641025641024},\n",
      " 'overall_accuracy': 0.9407820736199025,\n",
      " 'overall_f1': 0.5339831401475237,\n",
      " 'overall_precision': 0.5431404072883173,\n",
      " 'overall_recall': 0.5251295336787565}\n",
      "{'ALG': {'f1': 0.0, 'number': 53, 'precision': 0.0, 'recall': 0.0},\n",
      " 'APP': {'f1': 0.4263402279442803,\n",
      "         'number': 1224,\n",
      "         'precision': 0.4410480349344978,\n",
      "         'recall': 0.4125816993464052},\n",
      " 'CB': {'f1': 0.23049391553328558,\n",
      "        'number': 555,\n",
      "        'precision': 0.19121140142517815,\n",
      "        'recall': 0.29009009009009007},\n",
      " 'CLA': {'f1': 0.24345146379044685,\n",
      "         'number': 274,\n",
      "         'precision': 0.21066666666666667,\n",
      "         'recall': 0.28832116788321166},\n",
      " 'DEV': {'f1': 0.39999999999999997,\n",
      "         'number': 153,\n",
      "         'precision': 0.3888888888888889,\n",
      "         'recall': 0.4117647058823529},\n",
      " 'DS': {'f1': 0.632996632996633,\n",
      "        'number': 156,\n",
      "        'precision': 0.6666666666666666,\n",
      "        'recall': 0.6025641025641025},\n",
      " 'DT': {'f1': 0.33333333333333337,\n",
      "        'number': 85,\n",
      "        'precision': 0.38461538461538464,\n",
      "        'recall': 0.29411764705882354},\n",
      " 'FN': {'f1': 0.279646017699115,\n",
      "        'number': 227,\n",
      "        'precision': 0.23372781065088757,\n",
      "        'recall': 0.34801762114537443},\n",
      " 'FT': {'f1': 0.45398773006134974,\n",
      "        'number': 138,\n",
      "        'precision': 0.39361702127659576,\n",
      "        'recall': 0.5362318840579711},\n",
      " 'FUN': {'f1': 0.21925133689839574,\n",
      "         'number': 143,\n",
      "         'precision': 0.1774891774891775,\n",
      "         'recall': 0.2867132867132867},\n",
      " 'HXT': {'f1': 0.23529411764705882,\n",
      "         'number': 13,\n",
      "         'precision': 0.19047619047619047,\n",
      "         'recall': 0.3076923076923077},\n",
      " 'LAN': {'f1': 0.6681127982646421,\n",
      "         'number': 209,\n",
      "         'precision': 0.6111111111111112,\n",
      "         'recall': 0.7368421052631579},\n",
      " 'LIB': {'f1': 0.3407643312101911,\n",
      "         'number': 579,\n",
      "         'precision': 0.31610044313146235,\n",
      "         'recall': 0.3696027633851468},\n",
      " 'OS': {'f1': 0.8200589970501475,\n",
      "        'number': 175,\n",
      "        'precision': 0.8475609756097561,\n",
      "        'recall': 0.7942857142857143},\n",
      " 'UIE': {'f1': 0.5277777777777778,\n",
      "         'number': 282,\n",
      "         'precision': 0.5170068027210885,\n",
      "         'recall': 0.5390070921985816},\n",
      " 'UN': {'f1': 0.4431818181818181,\n",
      "        'number': 182,\n",
      "        'precision': 0.4588235294117647,\n",
      "        'recall': 0.42857142857142855},\n",
      " 'VAL': {'f1': 0.0, 'number': 0, 'precision': 0.0, 'recall': 0.0},\n",
      " 'VAR': {'f1': 0.1262975778546713,\n",
      "         'number': 348,\n",
      "         'precision': 0.09034653465346534,\n",
      "         'recall': 0.20977011494252873},\n",
      " 'VER': {'f1': 0.6700680272108843,\n",
      "         'number': 333,\n",
      "         'precision': 0.7725490196078432,\n",
      "         'recall': 0.5915915915915916},\n",
      " 'WEB': {'f1': 0.4298245614035088,\n",
      "         'number': 145,\n",
      "         'precision': 0.5903614457831325,\n",
      "         'recall': 0.33793103448275863},\n",
      " 'overall_accuracy': 0.9055527573204101,\n",
      " 'overall_f1': 0.362202109109026,\n",
      " 'overall_precision': 0.3222041660511154,\n",
      " 'overall_recall': 0.41353811149032993}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "def get_dct(x, text):\n",
    "    pred = np.argmax(x.predictions, axis=2)\n",
    "    dct = compute_metrics((pred, tokenized_ds[text][\"labels\"]), True)\n",
    "    with open(f'codellama_{text}.pickle', 'wb') as f:\n",
    "        pickle.dump(dct, f)\n",
    "\n",
    "    return dct\n",
    "\n",
    "pprint(get_dct(a, \"validation\"))\n",
    "pprint(get_dct(b, \"test\"))\n",
    "pprint(get_dct(c, \"gh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78470833-b452-4566-be01-3d3aff8c62e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeGen",
   "language": "python",
   "name": "codegen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
